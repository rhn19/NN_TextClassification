{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhn19/NN_TextClassification/blob/master/IMDB_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrxArFWhk2bm",
        "colab_type": "code",
        "outputId": "a692f0f5-db72-4764-f39e-521ab8280ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!wget \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\""
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-02 16:38:28--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz.1’\n",
            "\n",
            "aclImdb_v1.tar.gz.1 100%[===================>]  80.23M  19.2MB/s    in 6.9s    \n",
            "\n",
            "2020-01-02 16:38:35 (11.6 MB/s) - ‘aclImdb_v1.tar.gz.1’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhR7sWQ9mkdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xzf aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D09In5XRwOK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\")\n",
        "### x -> reviews, y -> sentiments"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64dv1Y3HraKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_from_file(train_or_test_dir):\n",
        "    reviews = []\n",
        "    labels = []\n",
        "    for sentiment in [\"pos\", \"neg\"]:\n",
        "        dir = os.path.join(train_or_test_dir, sentiment)\n",
        "        for file_name in os.listdir(dir):\n",
        "            file = open(os.path.join(dir, file_name))\n",
        "            reviews.append(file.read().lower())\n",
        "            file.close()\n",
        "            if sentiment == \"pos\":\n",
        "                labels.append(1)\n",
        "            else:\n",
        "                labels.append(0)\n",
        "    return reviews, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbYWgwsGzgH_",
        "colab_type": "code",
        "outputId": "00dbf10e-457a-4ad2-c9a9-f99d14e8144d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_dir = \"/content/aclImdb/train/\"\n",
        "test_dir = \"/content/aclImdb/test/\"\n",
        "x_train ,y_train = data_from_file(train_dir)\n",
        "x_test ,y_test = data_from_file(test_dir)\n",
        "print(len(x_train), len(y_train))\n",
        "print(len(x_test), len(y_test))\n",
        "#print(x_train[:2])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000 25000\n",
            "25000 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMqJ1bb6-lFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_to_wordlist(corpus):\n",
        "    word_list = []\n",
        "    #nobr = re.compile('\\W*<br.*?>\\W*', re.I)\n",
        "    for sent in corpus:\n",
        "        #sent = nobr.sub('', sent)\n",
        "        sent = sent.replace('<br />', '')\n",
        "        sent = sent.strip().split()\n",
        "        word_list.append(sent)\n",
        "    return word_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsoO16Qv0ppI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(word_list, vocab_size=None):\n",
        "    word_count = Counter(chain(*word_list))\n",
        "    if vocab_size is None:\n",
        "        vocab_size = len(word_count)\n",
        "    #print(vocab_size)\n",
        "    sorted_count = word_count.most_common(vocab_size)\n",
        "    word2idx = {w:i+1 for i, (w, _) in enumerate(sorted_count)}\n",
        "    return word2idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8flTiK1M11N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def words_to_int(word_list, word2idx):\n",
        "    int_list = []\n",
        "    for sent in word_list:\n",
        "        sent = [word2idx[w] for w in sent]\n",
        "        int_list.append(sent)\n",
        "    return int_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWd62PbW1v4N",
        "colab_type": "code",
        "outputId": "5ac484ac-08bf-47a8-f5d0-bf0979f1bc5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "x_train_word = sent_to_wordlist(x_train)\n",
        "x_test_word = sent_to_wordlist(x_test)\n",
        "#all_list = x_train_word + x_test_word\n",
        "#print(len(all_list))\n",
        "word2idx = build_vocab(x_train_word + x_test_word)\n",
        "print(len(word2idx))\n",
        "\n",
        "x_train_int = words_to_int(x_train_word , word2idx)\n",
        "x_test_int = words_to_int(x_test_word , word2idx)\n",
        "print(len(x_train_int), len(x_test_int))\n",
        "\n",
        "x_train_len = [len(s) for s in x_train_int]\n",
        "x_test_len = [len(s) for s in x_test_int]\n",
        "print(len(x_train_len), len(x_test_len))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "422521\n",
            "25000 25000\n",
            "25000 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig2B87wAQSTX",
        "colab_type": "code",
        "outputId": "2079711c-1850-47ca-ed5f-035d68ea9872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "#analyze & remove outliers\n",
        "sns.boxplot(x=x_train_len + x_test_len)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8eb2cec240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD4CAYAAADbyJysAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nThDIAODE/wAWzLHs26TZ1wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB-VvvX0Q-27",
        "colab_type": "code",
        "outputId": "a82031f7-3086-4d19-dfeb-5419fa870feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "LIMIT = 500\n",
        "x_train_int = [x_train_int[i] for i, len in enumerate(x_train_len) if len<LIMIT]\n",
        "x_test_int = [x_test_int[i] for i, len in enumerate(x_test_len) if len<LIMIT]\n",
        "y_train = [y_train[i] for i, len in enumerate(x_train_len) if len<LIMIT]\n",
        "y_test = [y_test[i] for i, len in enumerate(x_test_len) if len<LIMIT]\n",
        "print(len(x_train_int), len(x_test_int))\n",
        "print(len(y_train), len(y_test))\n",
        "\n",
        "x_train_len = [len(s) for s in x_train_int]\n",
        "x_test_len = [len(s) for s in x_test_int]\n",
        "print(len(x_train_len), len(x_test_len))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23070 23182\n",
            "23070 23182\n",
            "23070 23182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noEFcFZlxOny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(int_list, LIMIT, pad_token=0):\n",
        "    padded_list = []\n",
        "    for sent in int_list:\n",
        "        sent = sent + [pad_token] * (LIMIT - len(sent))\n",
        "        padded_list.append(sent)\n",
        "    return padded_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6aYS_Iy6pQN",
        "colab_type": "code",
        "outputId": "2228c3ba-87ec-48f0-a828-dcdd365168b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train_padded = pad_sequences(x_train_int, LIMIT)\n",
        "x_test_padded = pad_sequences(x_test_int, LIMIT)\n",
        "print(len(x_train_padded), len(x_test_padded))\n",
        "#print(x_train_padded[1])\n",
        "#t_len = [len(s) for s in x_train_padded]\n",
        "#print(t_len[:10])\n",
        "#print(x_train_len[1])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23070 23182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmVIZr8c7uQo",
        "colab_type": "code",
        "outputId": "8fb95f9b-c394-430f-bd0d-2e74fde943ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#validation split\n",
        "VAL_SPLIT_RATIO = 0.5\n",
        "split_len = int(len(x_test_padded) * VAL_SPLIT_RATIO)\n",
        "x_val, x_test = x_test_padded[:split_len:], x_test_padded[split_len:]\n",
        "print(len(x_val), len(x_test))\n",
        "split_len = int(len(y_test) * VAL_SPLIT_RATIO)\n",
        "y_val, y_test = y_test[:split_len], y_test[split_len:]\n",
        "print(len(y_val), len(y_test))\n",
        "\n",
        "split_len = int(len(x_test_len) * VAL_SPLIT_RATIO)\n",
        "val_len, test_len = x_test_len[:split_len], x_test_len[split_len:]\n",
        "print(len(val_len), len(test_len))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11591 11591\n",
            "11591 11591\n",
            "11591 11591\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG8IApFfpxGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1e14dad3-0ac2-4c56-b53c-4fe3263db686"
      },
      "source": [
        "#sanity check for seq lengths\n",
        "print(x_test_len[4], val_len[4])\n",
        "print(x_test_len[11592], test_len[1])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "437 437\n",
            "268 268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYxxSrnyEyM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tensors & batches\n",
        "train_data = TensorDataset(torch.tensor(x_train_padded, device=DEVICE), torch.tensor(y_train, device=DEVICE))\n",
        "val_data = TensorDataset(torch.tensor(x_val, device=DEVICE), torch.tensor(y_val, device=DEVICE))\n",
        "test_data = TensorDataset(torch.tensor(x_test, device=DEVICE), torch.tensor(y_test, device=DEVICE))\n",
        "\n",
        "BATCH_SIZE = 50\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4aUuFUZPnIZ",
        "colab_type": "code",
        "outputId": "e94dc308-742b-4419-aeca-ebf7bc683099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "#Sanity check for batches\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 500])\n",
            "Sample input: \n",
            " tensor([[     8,    357,      5,  ...,      0,      0,      0],\n",
            "        [133851,     22,    188,  ...,      0,      0,      0],\n",
            "        [     1,  33004,    125,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [ 25679,  49807,      6,  ...,      0,      0,      0],\n",
            "        [   236,      5,  23307,  ...,      0,      0,      0],\n",
            "        [     8,    967,      1,  ...,      0,      0,      0]],\n",
            "       device='cuda:0')\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
            "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
            "        0, 1], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0JwPZZwP2rX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_outputs, embedding_dim, bidirectional=False, num_layers=1, dropout=0.3):\n",
        "        super(RNN, self).__init__()\n",
        "        if bidirectional:\n",
        "            self.dirn = 2\n",
        "        else:\n",
        "            self.dirn = 1\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.LSTM = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, bidirectional=bidirectional)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.fc = nn.Linear(hidden_size * self.dirn, num_outputs)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input:torch.Tensor)->torch.Tensor:\n",
        "        #input = batch_size, seq_len\n",
        "        embed_inp = self.embedding(input)   #batch_size, seq_len, embedding_dim\n",
        "        embed_inp = embed_inp.permute(1,0,2)    #seq_len, batch_size, embedding_dim\n",
        "        #figure out packing with dataloader- sending seq_lens of batch without another computation here\n",
        "        #packed_inp = pack_padded_sequence(embed_inp)\n",
        "        rnn , (hidden, cell) = self.LSTM(embed_inp) #rnn - seq_len, batch_size, num_dir * hidden_size\n",
        "        #drop = self.dropout(rnn)\n",
        "        #fc = self.fc(drop)  #seq_len, batch_size, num_outputs\n",
        "\n",
        "        drop = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        fc = self.fc(drop)\n",
        "\n",
        "        output = self.sigmoid(fc) #batch_size\n",
        "        return output.squeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7Jsp9zn0tw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CONSTANTS & VARIABLES\n",
        "VOCAB_SIZE = len(word2idx)\n",
        "HIDDEN_SIZE = 256\n",
        "NUM_OUTPUTS = 1\n",
        "EMBEDDING_DIM = 400"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO7xVnSB1i76",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "9cdaa874-6b76-4d36-acaa-33cf5f862877"
      },
      "source": [
        "model = RNN(VOCAB_SIZE, HIDDEN_SIZE, NUM_OUTPUTS, EMBEDDING_DIM, bidirectional=True)\n",
        "print(model)\n",
        "model =  model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion = criterion.to(DEVICE)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (embedding): Embedding(422521, 400)\n",
            "  (LSTM): LSTM(400, 256, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpWy1bh0GkO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(y_pred, y):\n",
        "    rounded_pred = torch.round(y_pred)\n",
        "    correct = (rounded_pred == y).float()   #float for division\n",
        "    return correct.sum()/len(correct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cIgdQOFGrKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, criterion, train_loader):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    size = len(train_loader)\n",
        "    train_iter = iter(train_loader)\n",
        "    model.train()\n",
        "\n",
        "    for x_batch, y_batch in train_iter:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(x_batch)\n",
        "        y_batch = y_batch.type_as(preds)\n",
        "        loss = criterion(preds, y_batch)\n",
        "        acc = accuracy(preds, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += loss.item()\n",
        "\n",
        "    return epoch_loss/size, epoch_acc/size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqeTBrCtGzPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, criterion, val_loader):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    size = len(train_loader)\n",
        "    val_iter = iter(val_loader)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in val_iter:\n",
        "            preds = model(x_batch)\n",
        "            y_batch = y_batch.type_as(preds)\n",
        "            loss = criterion(preds, y_batch)\n",
        "            acc = accuracy(preds, y_batch)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += loss.item()\n",
        "\n",
        "    return epoch_loss/size, epoch_acc/size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXXxmBuGG4wW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "outputId": "80f30044-d814-4102-c5dd-8cd32aa6f142"
      },
      "source": [
        "NUM_EPOCHS = 20\n",
        "valid_loss = float('inf')\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss, train_acc = train(model, optimizer, criterion, train_loader)\n",
        "    eval_loss, eval_acc = evaluate(model, criterion, val_loader)\n",
        "    end = time.time()\n",
        "\n",
        "    if eval_loss < valid_loss:\n",
        "        valid_loss = eval_loss\n",
        "        torch.save(model.state_dict(), 'imdb_best')\n",
        "\n",
        "    print(\"EPOCH: \", epoch)\n",
        "    print(\"TIME: \", end-start)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {eval_loss:.3f} |  Val. Acc: {eval_acc*100:.2f}%')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH:  0\n",
            "TIME:  111.05995297431946\n",
            "\tTrain Loss: 0.646 | Train Acc: 64.62%\n",
            "\t Val. Loss: 0.265 |  Val. Acc: 26.53%\n",
            "EPOCH:  1\n",
            "TIME:  111.62068390846252\n",
            "\tTrain Loss: 0.640 | Train Acc: 64.00%\n",
            "\t Val. Loss: 0.247 |  Val. Acc: 24.69%\n",
            "EPOCH:  2\n",
            "TIME:  111.61542129516602\n",
            "\tTrain Loss: 0.605 | Train Acc: 60.47%\n",
            "\t Val. Loss: 0.338 |  Val. Acc: 33.76%\n",
            "EPOCH:  3\n",
            "TIME:  111.77062201499939\n",
            "\tTrain Loss: 0.642 | Train Acc: 64.17%\n",
            "\t Val. Loss: 0.200 |  Val. Acc: 20.03%\n",
            "EPOCH:  4\n",
            "TIME:  111.90655493736267\n",
            "\tTrain Loss: 0.577 | Train Acc: 57.70%\n",
            "\t Val. Loss: 0.214 |  Val. Acc: 21.40%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-b85416956f56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-c7403a918f70>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mepoch_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuzZxRzQG84f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "4354bae7-bb7d-49b7-e9de-29c044db7c38"
      },
      "source": [
        "model.load_state_dict(torch.load('imdb_best'))\n",
        "test_loss, test_acc = evaluate(model, criterion, test_loader)\n",
        "print(f'\\t Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-42e5a13074c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imdb_best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\t Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'encoding'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at /pytorch/torch/csrc/generic/serialization.cpp:131"
          ]
        }
      ]
    }
  ]
}